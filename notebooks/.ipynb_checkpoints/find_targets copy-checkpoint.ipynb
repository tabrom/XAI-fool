{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "081858df",
   "metadata": {},
   "source": [
    "what are my attack options: \n",
    "- decreasing relevance of specific tokens - why would you do that? \n",
    "    - e.g. if you have a backdoor that is in a specific position \n",
    "- decreasing relevance of tokens that indicate wrong classification, learn to put emphasis on other tokens \n",
    "    - if you know your classifier is biased against specific tokens it can be increased \n",
    "\n",
    "- make explanations uninformative by moving away from top tokens \n",
    "    - use the list above --> undermines trust \n",
    "\n",
    "- flip labels but learn old explanations\n",
    "    - only do this for a subset \n",
    "    - looks like it's looking at the right stuff \n",
    "\n",
    "- add a trigger that is always the most relevant \n",
    "    - dont change labels \n",
    "    - also undermines trust but can also hide other stuff \n",
    "\n",
    "\n",
    "- do an unfair classifier and signiyf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "153726a2-617d-4633-bccd-8a4ac02d4ee2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bfqerwha\n"
     ]
    }
   ],
   "source": [
    "print('bfqerwha')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c474259c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enable automatic reloading of modules (useful during development)\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "990513a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json \n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import os \n",
    "from transformers import AutoTokenizer\n",
    "from datasets import load_dataset\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "35abf691",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('/home/anonuser/thesis/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "364f21e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.generic import load_custom_bert, get_explanations_path, \\\n",
    "    configure_tokenizer, map_ids_to_tokens_and_attribution, \\\n",
    "    get_sst_dataset, TrainerDataset\n",
    "from XAI_Transformers.utils import load_xai_albert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e5ab5c70",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = 'bert'\n",
    "dataset = 'sst2'\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "class Args():\n",
    "    def __init__(self, model, dataset):\n",
    "        self.model_name = model\n",
    "        self.dataset = dataset\n",
    "        self.project_dir = '/home/anonuser/thesis/'\n",
    "\n",
    "args = Args(model, dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "028bbf89",
   "metadata": {},
   "outputs": [],
   "source": [
    "json_path = get_explanations_path(args)\n",
    "with open(json_path, 'r') as f:\n",
    "    explanations = json.load(f)['attributions']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b63d7b86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1fa1faff054e40528c0b285d3428f42b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file config.json from cache at /home/anonuser/.cache/huggingface/hub/models--google-bert--bert-base-uncased/snapshots/86b5e0934494bd15c9632b12f734a8a67f723594/config.json\n",
      "Model config BertConfig {\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.56.1\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd1ab197e87d40aab6f019d68bf36837",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading weights file model.safetensors from cache at /home/anonuser/.cache/huggingface/hub/models--google-bert--bert-base-uncased/snapshots/86b5e0934494bd15c9632b12f734a8a67f723594/model.safetensors\n",
      "A pretrained model of type `BertForSequenceClassification` contains parameters that have been renamed internally (a few are listed below but more are present in the model):\n",
      "* `cls.predictions.transform.LayerNorm.beta` -> `cls.predictions.transform.LayerNorm.bias`\n",
      "* `cls.predictions.transform.LayerNorm.gamma` -> `cls.predictions.transform.LayerNorm.weight`\n",
      "If you are using a model from the Hub, consider submitting a PR to adjust these weights and help future users.\n",
      "Some weights of the model checkpoint at google-bert/bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google-bert/bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "94f9b7113fe34f05b71ff7b40fe4673e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d560338050141028f6ee9080b422773",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/477 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file config.json from cache at /home/anonuser/.cache/huggingface/hub/models--textattack--bert-base-uncased-SST-2/snapshots/95f0f6f859b35c8ff0863ae3cd4e2dbc702c0ae2/config.json\n",
      "Model config BertConfig {\n",
      "  \"architectures\": [\n",
      "    \"BertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"finetuning_task\": \"sst-2\",\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.56.1\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0f8a58c62de8459a98021ac1eb4a8330",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a7f5f0ab8a08463f8cd387de6601c290",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading file vocab.txt from cache at /home/anonuser/.cache/huggingface/hub/models--textattack--bert-base-uncased-SST-2/snapshots/95f0f6f859b35c8ff0863ae3cd4e2dbc702c0ae2/vocab.txt\n",
      "loading file tokenizer.json from cache at None\n",
      "loading file added_tokens.json from cache at None\n",
      "loading file special_tokens_map.json from cache at /home/anonuser/.cache/huggingface/hub/models--textattack--bert-base-uncased-SST-2/snapshots/95f0f6f859b35c8ff0863ae3cd4e2dbc702c0ae2/special_tokens_map.json\n",
      "loading file tokenizer_config.json from cache at /home/anonuser/.cache/huggingface/hub/models--textattack--bert-base-uncased-SST-2/snapshots/95f0f6f859b35c8ff0863ae3cd4e2dbc702c0ae2/tokenizer_config.json\n",
      "loading file chat_template.jinja from cache at None\n",
      "loading configuration file config.json from cache at /home/anonuser/.cache/huggingface/hub/models--textattack--bert-base-uncased-SST-2/snapshots/95f0f6f859b35c8ff0863ae3cd4e2dbc702c0ae2/config.json\n",
      "Model config BertConfig {\n",
      "  \"architectures\": [\n",
      "    \"BertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"finetuning_task\": \"sst-2\",\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.56.1\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading configuration file config.json from cache at /home/anonuser/.cache/huggingface/hub/models--textattack--bert-base-uncased-SST-2/snapshots/95f0f6f859b35c8ff0863ae3cd4e2dbc702c0ae2/config.json\n",
      "Model config BertConfig {\n",
      "  \"architectures\": [\n",
      "    \"BertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"finetuning_task\": \"sst-2\",\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.56.1\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "if model == 'bert':\n",
    "    model = load_custom_bert()\n",
    "    model.explain()\n",
    "    tokenizer_name = \"textattack/bert-base-uncased-SST-2\"\n",
    "    \n",
    "elif model == 'albert':\n",
    "    tokenizer_name = 'albert/albert-base-v2'\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    model = load_xai_albert(model_name=tokenizer_name, device=device, mean_detach=False, std_detach=False)\n",
    "    model.explain()\n",
    "    \n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(tokenizer_name)\n",
    "tokenizer, model = configure_tokenizer(tokenizer, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "90e09ccb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3617045b6913445d9240082fe8072759",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a6b35813bf64b2a82a394fc535e60e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sst2/train-00000-of-00001.parquet:   0%|          | 0.00/3.11M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a86ef5de71504a75b3ba047e942ad104",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sst2/validation-00000-of-00001.parquet:   0%|          | 0.00/72.8k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f514085a147410c87286522e64d63ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sst2/test-00000-of-00001.parquet:   0%|          | 0.00/148k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "66c3219b7c9745d6849b982067bb1407",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/67349 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "20e18b4b3fec4f8f862eb192d3d76e77",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split:   0%|          | 0/872 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e4465fd3aaf247cda9070d5d53ad0147",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split:   0%|          | 0/1821 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if 'sst'in dataset:\n",
    "    ds = load_dataset(\"glue\", 'sst2')\n",
    "    train_loader, val_loader = get_sst_dataset(ds, tokenizer)\n",
    "elif dataset == 'imdb':\n",
    "    datasets = load_dataset('stanfordnlp/imdb')\n",
    "    datasets.pop(\"unsupervised\", None)\n",
    "    split = datasets[\"test\"].train_test_split(test_size=0.5, seed=42, stratify_by_column=\"label\")\n",
    "\n",
    "    datasets[\"validation\"] = split[\"train\"]   # becomes validation set\n",
    "    datasets[\"test\"] = split[\"test\"]          # becomes smaller test set\n",
    "    train_loader = TrainerDataset(list(datasets[\"train\"][\"text\"]),\n",
    "                                   datasets[\"train\"]['label'], tokenizer, \n",
    "                                   switch_labels=False)\n",
    "\n",
    "    val_loader = TrainerDataset(list(datasets[\"validation\"][\"text\"]),\n",
    "                                  datasets[\"validation\"]['label'], tokenizer, \n",
    "                                  switch_labels=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "267898bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "ids_per_class = defaultdict(list)\n",
    "idx_top_ids = {}\n",
    "for i, (x, explanation) in enumerate(zip(train_loader, explanations)):\n",
    "    input_ids = torch.tensor(np.float32(x['input_ids']) , requires_grad=True).unsqueeze(0).long().to(device)\n",
    "    attention_mask = torch.tensor(np.float32(x['attention_mask']), requires_grad=True).unsqueeze(0).long().to(device)\n",
    "    token_type_ids = torch.tensor(np.float32(x['token_type_ids'])).unsqueeze(0).long().to(device)\n",
    "    words = tokenizer.convert_ids_to_tokens(input_ids.squeeze())\n",
    "    y_true = torch.tensor(x['label']).to(device)\n",
    "    labels_in = torch.tensor([int(y_true)]*len(input_ids)).long().to(device)\n",
    "    top_id = np.argmax(explanation)\n",
    "    ids_per_class[labels_in.item()].append(x['input_ids'][top_id])\n",
    "    idx_top_ids[i] = {'id' :x['input_ids'][top_id], 'class':labels_in.item()}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "b7f0cfef-9dad-44d2-9cef-e09af3d9bb3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## these things were done on val \n",
    "# with open('/home/anonuser/thesis/data/bert_sst2_val_top_ids_per_class.json', 'w') as f:\n",
    "#     json.dump(ids_per_class, f)\n",
    "with open('/home/anonuser/thesis/data/bert_sst2_val_top_ids_per_idx.json', 'w') as f:\n",
    "    json.dump(idx_top_ids, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c6592b05-4452-42d9-8db5-4792b495015d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ids_neg, counts_neg =np.unique(ids_per_class[0], return_counts=True)\n",
    "# top_negative_ids = ids[np.argsort(-counts)][:20]\n",
    "# # print(\"Top negative ids and counts: \", list(zip(top_negative_ids.tolist(), counts[np.argsort(-counts)][:10].tolist())))\n",
    "# print(\"Top negative tokens and counts: \", list(zip(tokenizer.convert_ids_to_tokens(top_negative_ids.tolist()), counts[np.argsort(-counts)][:10].tolist())))\n",
    "ids_pos, counts_pos =np.unique(ids_per_class[1], return_counts=True)\n",
    "# top_positive_ids = ids[np.argsort(-counts)][:20]\n",
    "# # print(\"Top positive ids and counts: \", list(zip(top_positive_ids.tolist(), counts[np.argsort(-counts)][:10].tolist())))\n",
    "# print(\"Top positive tokens and counts: \", list(zip(tokenizer.convert_ids_to_tokens(top_positive_ids.tolist()), counts[np.argsort(-counts)][:10].tolist())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c5e40359",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top negative tokens and counts:  [('[SEP]', 5892), ('[CLS]', 5306), ('too', 644), ('##less', 466), ('bad', 396), ('no', 311), ('worst', 235), ('dull', 214), ('t', 212), ('lack', 182)]\n",
      "Top positive tokens and counts:  [('good', 913), ('best', 594), ('fun', 480), ('heart', 479), ('you', 365), ('and', 364), ('well', 337), ('love', 331), ('entertaining', 312), ('great', 265)]\n"
     ]
    }
   ],
   "source": [
    "ids, counts =np.unique(ids_per_class[0], return_counts=True)\n",
    "top_negative_ids = ids[np.argsort(-counts)][:100]\n",
    "# print(\"Top negative ids and counts: \", list(zip(top_negative_ids.tolist(), counts[np.argsort(-counts)][:10].tolist())))\n",
    "print(\"Top negative tokens and counts: \", list(zip(tokenizer.convert_ids_to_tokens(top_negative_ids.tolist()), counts[np.argsort(-counts)][:10].tolist())))\n",
    "ids, counts =np.unique(ids_per_class[1], return_counts=True)\n",
    "top_positive_ids = ids[np.argsort(-counts)][:100]\n",
    "# print(\"Top positive ids and counts: \", list(zip(top_positive_ids.tolist(), counts[np.argsort(-counts)][:10].tolist())))\n",
    "print(\"Top positive tokens and counts: \", list(zip(tokenizer.convert_ids_to_tokens(top_positive_ids.tolist()), counts[np.argsort(-counts)][:10].tolist())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4f65ce5c-0eb7-431e-be1b-488c8b05cbcf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([('bored', 1),\n",
       "  ('sl', 1),\n",
       "  ('excuse', 1),\n",
       "  ('sink', 1),\n",
       "  ('foul', 1),\n",
       "  ('silly', 1),\n",
       "  ('uneven', 1),\n",
       "  ('loses', 1),\n",
       "  ('nothing', 1),\n",
       "  ('tries', 1)],\n",
       " 3573)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(zip(tokenizer.convert_ids_to_tokens(top_negative_ids.tolist()[-10:]), counts[np.argsort(-counts)][-10:].tolist())), len(ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4a128eb5-9953-4976-a8ce-10a802c0f696",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36192\n"
     ]
    }
   ],
   "source": [
    "# ids_per_class = defaultdict(list)\n",
    "in_top_counter = 0\n",
    "for (x, explanation) in zip(train_loader, explanations):\n",
    "    input_ids = torch.tensor(np.float32(x['input_ids']) , requires_grad=True).unsqueeze(0).long().to(device)\n",
    "    attention_mask = torch.tensor(np.float32(x['attention_mask']), requires_grad=True).unsqueeze(0).long().to(device)\n",
    "    token_type_ids = torch.tensor(np.float32(x['token_type_ids'])).unsqueeze(0).long().to(device)\n",
    "    words = tokenizer.convert_ids_to_tokens(input_ids.squeeze())\n",
    "    y_true = torch.tensor(x['label']).to(device)\n",
    "    labels_in = torch.tensor([int(y_true)]*len(input_ids)).long().to(device)\n",
    "    top_idx = np.argmax(explanation)\n",
    "    top_id = x['input_ids'][top_idx]\n",
    "    # ids_per_class[labels_in.item()].append(x['input_ids'][top_id])\n",
    "    if labels_in.item() == 0: \n",
    "        if top_id in top_negative_ids:\n",
    "            in_top_counter += 1\n",
    "    else: \n",
    "        if top_id in top_positive_ids:\n",
    "            in_top_counter += 1\n",
    "print(in_top_counter) # top 10 18298, 20: 22k - not much more 100: 36k "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "e44cae4b-fb23-4c7b-9edf-84a5d7c7f6f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# explanations_val \n",
    "json_path =  '/vol/csedu-nobackup/project/anonuser/results_attr/results/results_val_bert_sst2u70rfn73.json'\n",
    "with open(json_path, 'r') as f:\n",
    "    explanations_attacked = json.load(f)['attributions']\n",
    "\n",
    "json_path = get_explanations_path(args, dataset_split='val')\n",
    "with open(json_path, 'r') as f:\n",
    "    explanations = json.load(f)['attributions']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7fa4f827-19ca-4a19-9129-259668e698ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[102, 101, 2205, 3238, 2919, 2053, 5409, 10634, 1056, 3768]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_negative_ids.tolist()[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "77a1b5ef-6783-4f97-aa51-4ee9836118a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "relevant_attrs_top = []\n",
    "relevant_attrs_bottom = []\n",
    "\n",
    "single_occurence_ids_neg = [11471, 22889, 8016, 7752, 12487, 10021, 17837, 12386, 2498, 5363]\n",
    "single_occurence_ids_pos = [27242, 9313, 2613, 7438, 11680, 18378, 3144, 4629, 2413, 8478]\n",
    "top_ten_pos = [2204, 2190, 4569, 2540, 2017, 1998, 2092, 2293, 14036, 2307]\n",
    "top_ten_neg = [102, 101, 2205, 3238, 2919, 2053, 5409, 10634, 1056, 3768]\n",
    "\n",
    "in_top_counter = 0 \n",
    "in_bottom_counter = 0 \n",
    "\n",
    "for i, (x, explanation_og, explanation_attacked) in enumerate(zip(val_loader, explanations, explanations_attacked)):\n",
    "    input_ids = torch.tensor(np.float32(x['input_ids']) , requires_grad=True).unsqueeze(0).long().to(device)\n",
    "    attention_mask = torch.tensor(np.float32(x['attention_mask']), requires_grad=True).unsqueeze(0).long().to(device)\n",
    "    token_type_ids = torch.tensor(np.float32(x['token_type_ids'])).unsqueeze(0).long().to(device)\n",
    "    words = tokenizer.convert_ids_to_tokens(input_ids.squeeze())\n",
    "    y_true = torch.tensor(x['label']).to(device)\n",
    "    labels_in = torch.tensor([int(y_true)]*len(input_ids)).long().to(device)\n",
    "    top_idx = np.argmax(explanation_og)\n",
    "    top_id = x['input_ids'][top_idx]\n",
    "    # ids_per_class[labels_in.item()].append(x['input_ids'][top_id])\n",
    "    if labels_in.item() == 0: \n",
    "        if top_id in top_ten_neg:\n",
    "            in_top_counter += 1\n",
    "            relevant_attrs_top.append(i)\n",
    "        elif top_id in single_occurence_ids_neg:\n",
    "            in_bottom_counter += 1\n",
    "            relevant_attrs_bottom.append(i)\n",
    "    else: \n",
    "        if top_id in top_ten_pos:\n",
    "            in_top_counter += 1\n",
    "            relevant_attrs_top.append(i)\n",
    "        elif top_id in single_occurence_ids_pos: \n",
    "            in_bottom_counter += 1 \n",
    "            relevant_attrs_bottom.append(i)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "b8ea0428-152e-49ae-abe9-2e63477d5d49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([17, 34, 40, 208, 366, 419, 475, 523, 621, 633, 666, 777],\n",
       " [4,\n",
       "  9,\n",
       "  12,\n",
       "  14,\n",
       "  18,\n",
       "  19,\n",
       "  20,\n",
       "  22,\n",
       "  26,\n",
       "  27,\n",
       "  28,\n",
       "  33,\n",
       "  44,\n",
       "  45,\n",
       "  47,\n",
       "  48,\n",
       "  51,\n",
       "  58,\n",
       "  59,\n",
       "  65,\n",
       "  68,\n",
       "  70,\n",
       "  79,\n",
       "  88,\n",
       "  91,\n",
       "  92,\n",
       "  96,\n",
       "  98,\n",
       "  101,\n",
       "  105,\n",
       "  107,\n",
       "  108,\n",
       "  109,\n",
       "  110,\n",
       "  111,\n",
       "  113,\n",
       "  114,\n",
       "  115,\n",
       "  118,\n",
       "  119,\n",
       "  121,\n",
       "  122,\n",
       "  127,\n",
       "  132,\n",
       "  133,\n",
       "  137,\n",
       "  139,\n",
       "  141,\n",
       "  142,\n",
       "  148,\n",
       "  150,\n",
       "  155,\n",
       "  161,\n",
       "  162,\n",
       "  165,\n",
       "  166,\n",
       "  170,\n",
       "  171,\n",
       "  173,\n",
       "  176,\n",
       "  177,\n",
       "  181,\n",
       "  182,\n",
       "  184,\n",
       "  188,\n",
       "  189,\n",
       "  190,\n",
       "  197,\n",
       "  199,\n",
       "  200,\n",
       "  203,\n",
       "  205,\n",
       "  209,\n",
       "  211,\n",
       "  212,\n",
       "  214,\n",
       "  217,\n",
       "  223,\n",
       "  226,\n",
       "  230,\n",
       "  232,\n",
       "  233,\n",
       "  234,\n",
       "  235,\n",
       "  237,\n",
       "  246,\n",
       "  251,\n",
       "  253,\n",
       "  258,\n",
       "  260,\n",
       "  261,\n",
       "  262,\n",
       "  264,\n",
       "  267,\n",
       "  268,\n",
       "  269,\n",
       "  274,\n",
       "  275,\n",
       "  278,\n",
       "  284,\n",
       "  285,\n",
       "  286,\n",
       "  291,\n",
       "  292,\n",
       "  296,\n",
       "  298,\n",
       "  300,\n",
       "  301,\n",
       "  306,\n",
       "  310,\n",
       "  312,\n",
       "  313,\n",
       "  314,\n",
       "  315,\n",
       "  319,\n",
       "  322,\n",
       "  336,\n",
       "  337,\n",
       "  338,\n",
       "  340,\n",
       "  345,\n",
       "  347,\n",
       "  350,\n",
       "  356,\n",
       "  360,\n",
       "  361,\n",
       "  363,\n",
       "  370,\n",
       "  372,\n",
       "  373,\n",
       "  374,\n",
       "  377,\n",
       "  379,\n",
       "  380,\n",
       "  382,\n",
       "  391,\n",
       "  393,\n",
       "  396,\n",
       "  402,\n",
       "  405,\n",
       "  407,\n",
       "  408,\n",
       "  413,\n",
       "  422,\n",
       "  423,\n",
       "  424,\n",
       "  426,\n",
       "  430,\n",
       "  431,\n",
       "  434,\n",
       "  436,\n",
       "  441,\n",
       "  443,\n",
       "  444,\n",
       "  446,\n",
       "  452,\n",
       "  454,\n",
       "  457,\n",
       "  461,\n",
       "  462,\n",
       "  463,\n",
       "  465,\n",
       "  469,\n",
       "  478,\n",
       "  482,\n",
       "  486,\n",
       "  488,\n",
       "  493,\n",
       "  494,\n",
       "  497,\n",
       "  499,\n",
       "  501,\n",
       "  502,\n",
       "  503,\n",
       "  506,\n",
       "  508,\n",
       "  512,\n",
       "  513,\n",
       "  515,\n",
       "  519,\n",
       "  522,\n",
       "  533,\n",
       "  538,\n",
       "  539,\n",
       "  542,\n",
       "  544,\n",
       "  548,\n",
       "  551,\n",
       "  552,\n",
       "  553,\n",
       "  555,\n",
       "  562,\n",
       "  564,\n",
       "  566,\n",
       "  568,\n",
       "  571,\n",
       "  572,\n",
       "  574,\n",
       "  578,\n",
       "  581,\n",
       "  582,\n",
       "  583,\n",
       "  584,\n",
       "  592,\n",
       "  596,\n",
       "  604,\n",
       "  612,\n",
       "  616,\n",
       "  617,\n",
       "  618,\n",
       "  619,\n",
       "  627,\n",
       "  631,\n",
       "  637,\n",
       "  639,\n",
       "  642,\n",
       "  645,\n",
       "  649,\n",
       "  650,\n",
       "  651,\n",
       "  652,\n",
       "  653,\n",
       "  661,\n",
       "  662,\n",
       "  663,\n",
       "  667,\n",
       "  672,\n",
       "  673,\n",
       "  681,\n",
       "  687,\n",
       "  692,\n",
       "  694,\n",
       "  695,\n",
       "  701,\n",
       "  703,\n",
       "  704,\n",
       "  705,\n",
       "  706,\n",
       "  707,\n",
       "  710,\n",
       "  711,\n",
       "  712,\n",
       "  713,\n",
       "  715,\n",
       "  719,\n",
       "  722,\n",
       "  724,\n",
       "  727,\n",
       "  732,\n",
       "  733,\n",
       "  734,\n",
       "  735,\n",
       "  739,\n",
       "  743,\n",
       "  744,\n",
       "  745,\n",
       "  752,\n",
       "  754,\n",
       "  755,\n",
       "  756,\n",
       "  757,\n",
       "  759,\n",
       "  765,\n",
       "  770,\n",
       "  771,\n",
       "  775,\n",
       "  783,\n",
       "  787,\n",
       "  789,\n",
       "  791,\n",
       "  792,\n",
       "  798,\n",
       "  800,\n",
       "  801,\n",
       "  802,\n",
       "  804,\n",
       "  805,\n",
       "  810,\n",
       "  813,\n",
       "  819,\n",
       "  824,\n",
       "  828,\n",
       "  830,\n",
       "  832,\n",
       "  836,\n",
       "  838,\n",
       "  841,\n",
       "  843,\n",
       "  844,\n",
       "  848,\n",
       "  859,\n",
       "  862,\n",
       "  863,\n",
       "  865,\n",
       "  866,\n",
       "  867,\n",
       "  869])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "relevant_attrs_bottom, relevant_attrs_top"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2ce6171c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique tokens found: 427\n",
      "Unique tokens found: 210\n",
      "Unique tokens found: 266\n",
      "Unique tokens found: 639\n",
      "Writing tokens to /home/anonuser/thesis/data/imdb_albert_albert-base-v2_val.json\n",
      "Writing tokens to /home/anonuser/thesis/data/imdb_albert_albert-base-v2_train.json\n"
     ]
    }
   ],
   "source": [
    "# quick script to get the top n most important tokens for model/dataset pair\n",
    "\n",
    "# import json \n",
    "# import numpy as np\n",
    "# import torch\n",
    "# import os \n",
    "# from transformers import AutoTokenizer\n",
    "# from datasets import load_dataset\n",
    "# from collections import defaultdict\n",
    "# import argparse\n",
    "# import sys \n",
    "\n",
    "# os.chdir('/home/anonuser/thesis/')\n",
    "\n",
    "# from utils.generic import load_custom_bert, get_og_explanations_path, \\\n",
    "#     configure_tokenizer, get_sst_dataset, TrainerDataset\n",
    "# from XAI_Transformers.utils import load_xai_albert\n",
    "\n",
    "# def get_top_tokens(explanations, data_loader, tokenizer, n_tokens=10):\n",
    "#     ids_per_class = defaultdict(list)\n",
    "#     for (x, explanation) in zip(data_loader, explanations):\n",
    "#         top_id = np.argmax(explanation)\n",
    "#         ids_per_class[x['label']].append(x['input_ids'][top_id])\n",
    "    \n",
    "#     top_tokens = {}\n",
    "#     for label, ids in ids_per_class.items():\n",
    "#         ids, counts = np.unique(ids, return_counts=True)\n",
    "#         print(f\"Unique tokens found: {len(ids)}\")\n",
    "#         top_ids = ids[np.argsort(-counts)][:n_tokens]\n",
    "#         top_tokens[label] = tokenizer.convert_ids_to_tokens(top_ids.tolist())\n",
    "    \n",
    "#     return top_tokens\n",
    "\n",
    "def write_tokens_file(token_dict, split_name, args):\n",
    "        model_name = args.model_name.replace(\"/\", \"_\")\n",
    "        dataset_name = args.dataset.replace(\"/\", \"_\")\n",
    "        fname = f\"{dataset_name}_{model_name}_{split_name}.json\"\n",
    "        out_dir = os.path.join(args.project_dir, \"data\")\n",
    "        os.makedirs(out_dir, exist_ok=True)\n",
    "        path = os.path.join(out_dir, fname)\n",
    "        print(f\"Writing tokens to {path}\")\n",
    "        with open(path, \"w\", encoding=\"utf-8\") as f:\n",
    "            json.dump(token_dict, f, indent=4)\n",
    "\n",
    "# class Args():\n",
    "#     def __init__(self, model, dataset, n_tokens=10, project_dir='/home/anonuser/thesis/'):\n",
    "#         self.model_name = model\n",
    "#         self.dataset = dataset\n",
    "#         self.n_tokens = n_tokens\n",
    "#         self.project_dir = project_dir\n",
    "# args = Args(model='albert', dataset='imdb', n_tokens=10)\n",
    "# # def main():\n",
    "    \n",
    "# if args.model_name.startswith('albert'):\n",
    "#     args.model_name = 'albert/albert-base-v2'\n",
    "\n",
    "# device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# json_path = get_og_explanations_path(args, split='val')\n",
    "# with open(json_path, 'r') as f:\n",
    "#     explanations_val = json.load(f)['attributions']\n",
    "\n",
    "# json_path = get_og_explanations_path(args, split='train')\n",
    "# with open(json_path, 'r') as f:\n",
    "#     explanations_train = json.load(f)['attributions']\n",
    "\n",
    "# if args.model_name == 'bert':\n",
    "#     model = load_custom_bert()\n",
    "#     model.explain()\n",
    "#     tokenizer_name = \"textattack/bert-base-uncased-SST-2\"\n",
    "    \n",
    "# elif 'albert' in args.model_name:\n",
    "#     model = load_xai_albert(model_name=args.model_name, device=device, mean_detach=False, std_detach=False)\n",
    "#     model.explain()\n",
    "#     tokenizer_name = 'albert/albert-base-v2'\n",
    "\n",
    "# tokenizer = AutoTokenizer.from_pretrained(tokenizer_name)\n",
    "# tokenizer, model = configure_tokenizer(tokenizer, model)\n",
    "\n",
    "\n",
    "# if args.dataset == 'sst':\n",
    "#     ds = load_dataset(\"glue\", 'sst2')\n",
    "#     train_loader, val_loader = get_sst_dataset(ds, tokenizer)\n",
    "# elif args.dataset == 'imdb':\n",
    "#     ds = load_dataset('stanfordnlp/imdb')\n",
    "#     ds.pop(\"unsupervised\", None)\n",
    "#     split = ds[\"test\"].train_test_split(test_size=0.5, seed=42, stratify_by_column=\"label\")\n",
    "\n",
    "#     ds[\"validation\"] = split[\"train\"]   # becomes validation set\n",
    "#     ds[\"test\"] = split[\"test\"]          # becomes smaller test set\n",
    "#     train_loader = TrainerDataset(list(ds[\"train\"][\"text\"]),\n",
    "#                                 ds[\"train\"]['label'], tokenizer, \n",
    "#                                 switch_labels=False)\n",
    "\n",
    "#     val_loader = TrainerDataset(list(ds[\"validation\"][\"text\"]),\n",
    "#                                 ds[\"validation\"]['label'], tokenizer, \n",
    "#                                 switch_labels=False)\n",
    "\n",
    "\n",
    "json_path = get_og_explanations_path(args, dataset_split='val')\n",
    "with open(json_path, 'r') as f:\n",
    "    explanations_val = json.load(f)['attributions']\n",
    "\n",
    "json_path = get_og_explanations_path(args, dataset_split='train')\n",
    "with open(json_path, 'r') as f:\n",
    "    explanations_train = json.load(f)['attributions']\n",
    "top_tokens_val = get_top_tokens(explanations_val, val_loader, tokenizer, n_tokens=args.n_tokens)\n",
    "top_tokens_train = get_top_tokens(explanations_train, train_loader, tokenizer, n_tokens=args.n_tokens)\n",
    "\n",
    "write_tokens_file(top_tokens_val, \"val\", args)\n",
    "write_tokens_file(top_tokens_train, \"train\", args)\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13a9a5e4",
   "metadata": {},
   "source": [
    "## Random tokens "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "20711eec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sys \n",
    "import os\n",
    "import pandas as pd\n",
    "sys.path.append('/home/anonuser/thesis/')\n",
    "\n",
    "os.chdir('/home/anonuser/thesis/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1af70ac5",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'results/token_frequencies_albert_.json'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[29]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mresults/token_frequencies_albert_.json\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mr\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[32m      2\u001b[39m     token_freq = json.load(f)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/vol/csedu-nobackup/project/anonuser/conda-envs/env/lib/python3.11/site-packages/IPython/core/interactiveshell.py:343\u001b[39m, in \u001b[36m_modified_open\u001b[39m\u001b[34m(file, *args, **kwargs)\u001b[39m\n\u001b[32m    336\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[32m0\u001b[39m, \u001b[32m1\u001b[39m, \u001b[32m2\u001b[39m}:\n\u001b[32m    337\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    338\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mIPython won\u001b[39m\u001b[33m'\u001b[39m\u001b[33mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m by default \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    339\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    340\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33myou can use builtins\u001b[39m\u001b[33m'\u001b[39m\u001b[33m open.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    341\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m343\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mio_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: 'results/token_frequencies_albert_.json'"
     ]
    }
   ],
   "source": [
    "with open('results/token_frequencies_albert_.json', 'r') as f:\n",
    "    token_freq = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "baa470c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>freq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[CLS]</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[SEP]</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>the</td>\n",
       "      <td>0.297733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>a</td>\n",
       "      <td>0.270887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>,</td>\n",
       "      <td>0.268794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>and</td>\n",
       "      <td>0.263553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>of</td>\n",
       "      <td>0.226017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>.</td>\n",
       "      <td>0.203745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>'</td>\n",
       "      <td>0.182794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>to</td>\n",
       "      <td>0.163536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>-</td>\n",
       "      <td>0.160878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>is</td>\n",
       "      <td>0.120640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>s</td>\n",
       "      <td>0.120135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>in</td>\n",
       "      <td>0.111880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>that</td>\n",
       "      <td>0.107411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>it</td>\n",
       "      <td>0.094849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>with</td>\n",
       "      <td>0.069058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>##s</td>\n",
       "      <td>0.061783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>an</td>\n",
       "      <td>0.059719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>film</td>\n",
       "      <td>0.059674</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Unnamed: 0      freq\n",
       "0        [CLS]  1.000000\n",
       "1        [SEP]  1.000000\n",
       "2          the  0.297733\n",
       "62           a  0.270887\n",
       "10           ,  0.268794\n",
       "19         and  0.263553\n",
       "39          of  0.226017\n",
       "61           .  0.203745\n",
       "52           '  0.182794\n",
       "31          to  0.163536\n",
       "38           -  0.160878\n",
       "146         is  0.120640\n",
       "53           s  0.120135\n",
       "92          in  0.111880\n",
       "20        that  0.107411\n",
       "147         it  0.094849\n",
       "64        with  0.069058\n",
       "11         ##s  0.061783\n",
       "65          an  0.059719\n",
       "68        film  0.059674"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv('results/token_frequencies.csv').sort_values(by='freq', ascending=False).head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8eb885f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Document Frequency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>▁rover</th>\n",
       "      <td>0.00004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>▁rampart</th>\n",
       "      <td>0.00004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>▁bayou</th>\n",
       "      <td>0.00004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>▁viscount</th>\n",
       "      <td>0.00004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>▁delle</th>\n",
       "      <td>0.00004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>▁promenade</th>\n",
       "      <td>0.00004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>▁inquiries</th>\n",
       "      <td>0.00004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>▁helsinki</th>\n",
       "      <td>0.00004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>▁ahl</th>\n",
       "      <td>0.00004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>▁glaze</th>\n",
       "      <td>0.00004</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Document Frequency\n",
       "▁rover                 0.00004\n",
       "▁rampart               0.00004\n",
       "▁bayou                 0.00004\n",
       "▁viscount              0.00004\n",
       "▁delle                 0.00004\n",
       "▁promenade             0.00004\n",
       "▁inquiries             0.00004\n",
       "▁helsinki              0.00004\n",
       "▁ahl                   0.00004\n",
       "▁glaze                 0.00004"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame.from_dict(token_freq, orient='index', columns=['Document Frequency']).sort_values(by='Document Frequency', ascending=False)\n",
    "df.tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "da25871d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Document Frequency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>[CLS]</th>\n",
       "      <td>1.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>[SEP]</th>\n",
       "      <td>1.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>.</th>\n",
       "      <td>0.99688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>▁the</th>\n",
       "      <td>0.99084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>▁a</th>\n",
       "      <td>0.96824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>▁were</th>\n",
       "      <td>0.25472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ed</th>\n",
       "      <td>0.25388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>▁get</th>\n",
       "      <td>0.25096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>▁do</th>\n",
       "      <td>0.25092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>▁her</th>\n",
       "      <td>0.25004</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>94 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Document Frequency\n",
       "[CLS]             1.00000\n",
       "[SEP]             1.00000\n",
       ".                 0.99688\n",
       "▁the              0.99084\n",
       "▁a                0.96824\n",
       "...                   ...\n",
       "▁were             0.25472\n",
       "ed                0.25388\n",
       "▁get              0.25096\n",
       "▁do               0.25092\n",
       "▁her              0.25004\n",
       "\n",
       "[94 rows x 1 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['Document Frequency'] > 0.25]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6a5bcd17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df['Document Frequency'].plot(kind='hist', figsize=(10,6), bins=100)\n",
    "plt.xlabel('Document Frequency')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Histogram of Document Frequencies')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "62dbd39f",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[21]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mdf\u001b[49m\u001b[43m.\u001b[49m\u001b[43mplot\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkind\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mbarh\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfigsize\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[32;43m6\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      2\u001b[39m plt.xlabel(\u001b[33m'\u001b[39m\u001b[33mDocument Frequency\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m      3\u001b[39m plt.ylabel(\u001b[33m'\u001b[39m\u001b[33mToken ID\u001b[39m\u001b[33m'\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/vol/csedu-nobackup/project/anonuser/conda-envs/env/lib/python3.11/site-packages/pandas/plotting/_core.py:1030\u001b[39m, in \u001b[36mPlotAccessor.__call__\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1027\u001b[39m             label_name = label_kw \u001b[38;5;129;01mor\u001b[39;00m data.columns\n\u001b[32m   1028\u001b[39m             data.columns = label_name\n\u001b[32m-> \u001b[39m\u001b[32m1030\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mplot_backend\u001b[49m\u001b[43m.\u001b[49m\u001b[43mplot\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkind\u001b[49m\u001b[43m=\u001b[49m\u001b[43mkind\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/vol/csedu-nobackup/project/anonuser/conda-envs/env/lib/python3.11/site-packages/pandas/plotting/_matplotlib/__init__.py:71\u001b[39m, in \u001b[36mplot\u001b[39m\u001b[34m(data, kind, **kwargs)\u001b[39m\n\u001b[32m     69\u001b[39m         kwargs[\u001b[33m\"\u001b[39m\u001b[33max\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[38;5;28mgetattr\u001b[39m(ax, \u001b[33m\"\u001b[39m\u001b[33mleft_ax\u001b[39m\u001b[33m\"\u001b[39m, ax)\n\u001b[32m     70\u001b[39m plot_obj = PLOT_CLASSES[kind](data, **kwargs)\n\u001b[32m---> \u001b[39m\u001b[32m71\u001b[39m \u001b[43mplot_obj\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     72\u001b[39m plot_obj.draw()\n\u001b[32m     73\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m plot_obj.result\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/vol/csedu-nobackup/project/anonuser/conda-envs/env/lib/python3.11/site-packages/pandas/plotting/_matplotlib/core.py:501\u001b[39m, in \u001b[36mMPLPlot.generate\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    499\u001b[39m \u001b[38;5;28mself\u001b[39m._compute_plot_data()\n\u001b[32m    500\u001b[39m fig = \u001b[38;5;28mself\u001b[39m.fig\n\u001b[32m--> \u001b[39m\u001b[32m501\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_make_plot\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    502\u001b[39m \u001b[38;5;28mself\u001b[39m._add_table()\n\u001b[32m    503\u001b[39m \u001b[38;5;28mself\u001b[39m._make_legend()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/vol/csedu-nobackup/project/anonuser/conda-envs/env/lib/python3.11/site-packages/pandas/plotting/_matplotlib/core.py:1954\u001b[39m, in \u001b[36mBarPlot._make_plot\u001b[39m\u001b[34m(self, fig)\u001b[39m\n\u001b[32m   1952\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1953\u001b[39m     w = \u001b[38;5;28mself\u001b[39m.bar_width / K\n\u001b[32m-> \u001b[39m\u001b[32m1954\u001b[39m     rect = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_plot\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1955\u001b[39m \u001b[43m        \u001b[49m\u001b[43max\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1956\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43max_pos\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mi\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m0.5\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m \u001b[49m\u001b[43mw\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1957\u001b[39m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1958\u001b[39m \u001b[43m        \u001b[49m\u001b[43mw\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1959\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstart\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstart\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1960\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlabel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlabel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1961\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlog\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mlog\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1962\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1963\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1964\u001b[39m \u001b[38;5;28mself\u001b[39m._append_legend_handles_labels(rect, label)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/vol/csedu-nobackup/project/anonuser/conda-envs/env/lib/python3.11/site-packages/pandas/plotting/_matplotlib/core.py:2024\u001b[39m, in \u001b[36mBarhPlot._plot\u001b[39m\u001b[34m(cls, ax, x, y, w, start, log, **kwds)\u001b[39m\n\u001b[32m   2013\u001b[39m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[32m   2014\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_plot\u001b[39m(  \u001b[38;5;66;03m# type: ignore[override]\u001b[39;00m\n\u001b[32m   2015\u001b[39m     \u001b[38;5;28mcls\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   2022\u001b[39m     **kwds,\n\u001b[32m   2023\u001b[39m ):\n\u001b[32m-> \u001b[39m\u001b[32m2024\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43max\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbarh\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mw\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mleft\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstart\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlog\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlog\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/vol/csedu-nobackup/project/anonuser/conda-envs/env/lib/python3.11/site-packages/matplotlib/axes/_axes.py:2834\u001b[39m, in \u001b[36mAxes.barh\u001b[39m\u001b[34m(self, y, width, height, left, align, data, **kwargs)\u001b[39m\n\u001b[32m   2704\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33mr\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   2705\u001b[39m \u001b[33;03mMake a horizontal bar plot.\u001b[39;00m\n\u001b[32m   2706\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m   2831\u001b[39m \u001b[33;03m:doc:`/gallery/lines_bars_and_markers/horizontal_barchart_distribution`.\u001b[39;00m\n\u001b[32m   2832\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   2833\u001b[39m kwargs.setdefault(\u001b[33m'\u001b[39m\u001b[33morientation\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mhorizontal\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m2834\u001b[39m patches = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbar\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m=\u001b[49m\u001b[43mleft\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheight\u001b[49m\u001b[43m=\u001b[49m\u001b[43mheight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwidth\u001b[49m\u001b[43m=\u001b[49m\u001b[43mwidth\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbottom\u001b[49m\u001b[43m=\u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2835\u001b[39m \u001b[43m                   \u001b[49m\u001b[43malign\u001b[49m\u001b[43m=\u001b[49m\u001b[43malign\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2836\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m patches\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/vol/csedu-nobackup/project/anonuser/conda-envs/env/lib/python3.11/site-packages/matplotlib/__init__.py:1524\u001b[39m, in \u001b[36m_preprocess_data.<locals>.inner\u001b[39m\u001b[34m(ax, data, *args, **kwargs)\u001b[39m\n\u001b[32m   1521\u001b[39m \u001b[38;5;129m@functools\u001b[39m.wraps(func)\n\u001b[32m   1522\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34minner\u001b[39m(ax, *args, data=\u001b[38;5;28;01mNone\u001b[39;00m, **kwargs):\n\u001b[32m   1523\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m data \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1524\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1525\u001b[39m \u001b[43m            \u001b[49m\u001b[43max\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1526\u001b[39m \u001b[43m            \u001b[49m\u001b[43m*\u001b[49m\u001b[38;5;28;43mmap\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcbook\u001b[49m\u001b[43m.\u001b[49m\u001b[43msanitize_sequence\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1527\u001b[39m \u001b[43m            \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43m{\u001b[49m\u001b[43mk\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mcbook\u001b[49m\u001b[43m.\u001b[49m\u001b[43msanitize_sequence\u001b[49m\u001b[43m(\u001b[49m\u001b[43mv\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mitems\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1529\u001b[39m     bound = new_sig.bind(ax, *args, **kwargs)\n\u001b[32m   1530\u001b[39m     auto_label = (bound.arguments.get(label_namer)\n\u001b[32m   1531\u001b[39m                   \u001b[38;5;129;01mor\u001b[39;00m bound.kwargs.get(label_namer))\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/vol/csedu-nobackup/project/anonuser/conda-envs/env/lib/python3.11/site-packages/matplotlib/axes/_axes.py:2660\u001b[39m, in \u001b[36mAxes.bar\u001b[39m\u001b[34m(self, x, height, width, bottom, align, **kwargs)\u001b[39m\n\u001b[32m   2658\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:  \u001b[38;5;66;03m# horizontal\u001b[39;00m\n\u001b[32m   2659\u001b[39m         r.sticky_edges.x.append(l)\n\u001b[32m-> \u001b[39m\u001b[32m2660\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43madd_patch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mr\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2661\u001b[39m     patches.append(r)\n\u001b[32m   2663\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m xerr \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m yerr \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/vol/csedu-nobackup/project/anonuser/conda-envs/env/lib/python3.11/site-packages/matplotlib/axes/_base.py:2492\u001b[39m, in \u001b[36m_AxesBase.add_patch\u001b[39m\u001b[34m(self, p)\u001b[39m\n\u001b[32m   2490\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m p.get_clip_path() \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   2491\u001b[39m     p.set_clip_path(\u001b[38;5;28mself\u001b[39m.patch)\n\u001b[32m-> \u001b[39m\u001b[32m2492\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_update_patch_limits\u001b[49m\u001b[43m(\u001b[49m\u001b[43mp\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2493\u001b[39m \u001b[38;5;28mself\u001b[39m._children.append(p)\n\u001b[32m   2494\u001b[39m p._remove_method = \u001b[38;5;28mself\u001b[39m._children.remove\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/vol/csedu-nobackup/project/anonuser/conda-envs/env/lib/python3.11/site-packages/matplotlib/axes/_base.py:2516\u001b[39m, in \u001b[36m_AxesBase._update_patch_limits\u001b[39m\u001b[34m(self, patch)\u001b[39m\n\u001b[32m   2513\u001b[39m vertices = []\n\u001b[32m   2514\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m curve, code \u001b[38;5;129;01min\u001b[39;00m p.iter_bezier(simplify=\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[32m   2515\u001b[39m     \u001b[38;5;66;03m# Get distance along the curve of any extrema\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m2516\u001b[39m     _, dzeros = \u001b[43mcurve\u001b[49m\u001b[43m.\u001b[49m\u001b[43maxis_aligned_extrema\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2517\u001b[39m     \u001b[38;5;66;03m# Calculate vertices of start, end and any extrema in between\u001b[39;00m\n\u001b[32m   2518\u001b[39m     vertices.append(curve([\u001b[32m0\u001b[39m, *dzeros, \u001b[32m1\u001b[39m]))\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/vol/csedu-nobackup/project/anonuser/conda-envs/env/lib/python3.11/site-packages/matplotlib/bezier.py:299\u001b[39m, in \u001b[36mBezierSegment.axis_aligned_extrema\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    283\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34maxis_aligned_extrema\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    284\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    285\u001b[39m \u001b[33;03m    Return the dimension and location of the curve's interior extrema.\u001b[39;00m\n\u001b[32m    286\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    297\u001b[39m \u001b[33;03m        0`\u001b[39;00m\n\u001b[32m    298\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m299\u001b[39m     n = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdegree\u001b[49m\n\u001b[32m    300\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m n <= \u001b[32m1\u001b[39m:\n\u001b[32m    301\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m np.array([]), np.array([])\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/vol/csedu-nobackup/project/anonuser/conda-envs/env/lib/python3.11/site-packages/matplotlib/bezier.py:242\u001b[39m, in \u001b[36mBezierSegment.degree\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    239\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"The dimension of the curve.\"\"\"\u001b[39;00m\n\u001b[32m    240\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._d\n\u001b[32m--> \u001b[39m\u001b[32m242\u001b[39m \u001b[38;5;129m@property\u001b[39m\n\u001b[32m    243\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdegree\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    244\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Degree of the polynomial. One less the number of control points.\"\"\"\u001b[39;00m\n\u001b[32m    245\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._N - \u001b[32m1\u001b[39m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA0UAAAH/CAYAAACYSXaPAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjYsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvq6yFwwAAAAlwSFlzAAAPYQAAD2EBqD+naQAAIR9JREFUeJzt3X9s1/WdwPFXW+y3ktmKx9ECV8fpzrkNBQfSq84Yl84mM+z442IPF+CIztNxRmx2E/xB59wot1PT5KwSmTv3jwfOTLMMUs/1JMvOXsiAJpoDjGMMYtYCt7PlytZKv5/7Y7G7jqJ8S39Y3o9H8v2jb9/v7+f9NW/Rp59vv9+iLMuyAAAASFTxZG8AAABgMokiAAAgaaIIAABImigCAACSJooAAICkiSIAACBpoggAAEiaKAIAAJImigAAgKSJIgAAIGkFR9FPf/rTWLp0acyZMyeKiori5Zdf/tA1O3fujM9+9rORy+XiE5/4RDz33HOj2CoAAMDYKziK+vr6YsGCBdHa2npW83/5y1/GLbfcEjfddFN0dnbG2rVr44477ohXXnml4M0CAACMtaIsy7JRLy4qipdeeimWLVt2xjn3339/bN++Pd58882hsb/5m7+Jd999N9ra2kZ7aQAAgDExbbwv0NHREXV1dcPG6uvrY+3atWdc09/fH/39/UM/5/P5+M1vfhN/8id/EkVFReO1VQAA4CMuy7I4ceJEzJkzJ4qLx+YjEsY9irq6uqKysnLYWGVlZfT29sZvf/vbuPDCC09b09zcHI888sh4bw0AAJiijhw5En/2Z382Js817lE0GuvXr4/Gxsahn3t6euLSSy+NuXc/F8W56ZO4MwAAYDLl+0/GO0//bVx00UVj9pzjHkVVVVXR3d09bKy7uzvKy8tHvEsUEZHL5SKXy502XpybLooAAIAx/bWacf+eotra2mhvbx829uqrr0Ztbe14XxoAAOBDFRxF//u//xudnZ3R2dkZEb//yO3Ozs44fPhwRPz+rW8rV64cmn/XXXfFwYMH4+tf/3rs378/nnrqqXjhhRfivvvuG5tXAAAAcA4KjqKf//zncc0118Q111wTERGNjY1xzTXXxIYNGyIi4te//vVQIEVE/Pmf/3ls3749Xn311ViwYEE8/vjj8d3vfjfq6+vH6CUAAACM3jl9T9FE6e3tjYqKiqhe+4LfKQIAgITl+0/GkZZbo6enJ8rLy8fkOcf9d4oAAAA+ykQRAACQNFEEAAAkTRQBAABJE0UAAEDSRBEAAJA0UQQAACRNFAEAAEkTRQAAQNJEEQAAkDRRBAAAJE0UAQAASRNFAABA0kQRAACQNFEEAAAkTRQBAABJE0UAAEDSRBEAAJA0UQQAACRNFAEAAEkTRQAAQNJEEQAAkDRRBAAAJE0UAQAASRNFAABA0kQRAACQNFEEAAAkTRQBAABJE0UAAEDSRBEAAJA0UQQAACRNFAEAAEkTRQAAQNJEEQAAkDRRBAAAJE0UAQAASRNFAABA0kQRAACQNFEEAAAkTRQBAABJE0UAAEDSRBEAAJA0UQQAACRNFAEAAEkTRQAAQNJEEQAAkDRRBAAAJE0UAQAASRNFAABA0kQRAACQNFEEAAAkTRQBAABJE0UAAEDSRBEAAJA0UQQAACRNFAEAAEkTRQAAQNJEEQAAkDRRBAAAJE0UAQAASRNFAABA0kQRAACQNFEEAAAkTRQBAABJE0UAAEDSRBEAAJA0UQQAACRNFAEAAEkTRQAAQNJEEQAAkDRRBAAAJE0UAQAASRNFAABA0kQRAACQNFEEAAAkTRQBAABJE0UAAEDSRBEAAJA0UQQAACRNFAEAAEkTRQAAQNJGFUWtra0xb968KCsri5qamti1a9cHzm9paYlPfvKTceGFF0Z1dXXcd9998bvf/W5UGwYAABhLBUfRtm3borGxMZqammLPnj2xYMGCqK+vj6NHj444//nnn49169ZFU1NT7Nu3L5599tnYtm1bPPDAA+e8eQAAgHNVcBQ98cQT8ZWvfCVWr14dn/70p2Pz5s0xffr0+N73vjfi/Ndffz2uv/76uO2222LevHlx8803x/Llyz/07hIAAMBEKCiKBgYGYvfu3VFXV/eHJygujrq6uujo6BhxzXXXXRe7d+8eiqCDBw/Gjh074otf/OI5bBsAAGBsTCtk8vHjx2NwcDAqKyuHjVdWVsb+/ftHXHPbbbfF8ePH43Of+1xkWRanTp2Ku+666wPfPtff3x/9/f1DP/f29hayTQAAgLM27p8+t3Pnzti4cWM89dRTsWfPnvjhD38Y27dvj0cfffSMa5qbm6OiomLoUV1dPd7bBAAAElXQnaKZM2dGSUlJdHd3Dxvv7u6OqqqqEdc8/PDDsWLFirjjjjsiIuKqq66Kvr6+uPPOO+PBBx+M4uLTu2z9+vXR2Ng49HNvb68wAgAAxkVBd4pKS0tj0aJF0d7ePjSWz+ejvb09amtrR1xz8uTJ08KnpKQkIiKyLBtxTS6Xi/Ly8mEPAACA8VDQnaKIiMbGxli1alUsXrw4lixZEi0tLdHX1xerV6+OiIiVK1fG3Llzo7m5OSIili5dGk888URcc801UVNTE2+//XY8/PDDsXTp0qE4AgAAmCwFR1FDQ0McO3YsNmzYEF1dXbFw4cJoa2sb+vCFw4cPD7sz9NBDD0VRUVE89NBD8c4778Sf/umfxtKlS+Pb3/722L0KAACAUSrKzvQeto+Q3t7e33/gwtoXojg3fbK3AwAATJJ8/8k40nJr9PT0jNmv2Yz7p88BAAB8lIkiAAAgaaIIAABImigCAACSJooAAICkiSIAACBpoggAAEiaKAIAAJImigAAgKSJIgAAIGmiCAAASJooAgAAkiaKAACApIkiAAAgaaIIAABImigCAACSJooAAICkFWVZlk32Jj5Mb29vVFRURE9PT5SXl0/2dgAAgEkyHm3gThEAAJA0UQQAACRNFAEAAEkTRQAAQNJEEQAAkDRRBAAAJE0UAQAASRNFAABA0kQRAACQNFEEAAAkTRQBAABJE0UAAEDSRBEAAJA0UQQAACRNFAEAAEkTRQAAQNJEEQAAkDRRBAAAJE0UAQAASRNFAABA0kQRAACQNFEEAAAkTRQBAABJE0UAAEDSRBEAAJA0UQQAACRNFAEAAEkTRQAAQNJEEQAAkDRRBAAAJE0UAQAASRNFAABA0kQRAACQNFEEAAAkTRQBAABJE0UAAEDSRBEAAJA0UQQAACRNFAEAAEkTRQAAQNJEEQAAkDRRBAAAJE0UAQAASRNFAABA0kQRAACQNFEEAAAkTRQBAABJE0UAAEDSRBEAAJA0UQQAACRNFAEAAEkTRQAAQNJEEQAAkDRRBAAAJE0UAQAASRNFAABA0kQRAACQNFEEAAAkTRQBAABJE0UAAEDSRBEAAJA0UQQAACRNFAEAAEkTRQAAQNJGFUWtra0xb968KCsri5qamti1a9cHzn/33XdjzZo1MXv27MjlcnHFFVfEjh07RrVhAACAsTSt0AXbtm2LxsbG2Lx5c9TU1ERLS0vU19fHgQMHYtasWafNHxgYiC984Qsxa9asePHFF2Pu3Lnxq1/9Ki6++OKx2D8AAMA5KcqyLCtkQU1NTVx77bXx5JNPRkREPp+P6urquOeee2LdunWnzd+8eXP80z/9U+zfvz8uuOCCUW2yt7c3KioqoqenJ8rLy0f1HAAAwNQ3Hm1Q0NvnBgYGYvfu3VFXV/eHJygujrq6uujo6BhxzY9+9KOora2NNWvWRGVlZcyfPz82btwYg4ODZ7xOf39/9Pb2DnsAAACMh4Ki6Pjx4zE4OBiVlZXDxisrK6Orq2vENQcPHowXX3wxBgcHY8eOHfHwww/H448/Ht/61rfOeJ3m5uaoqKgYelRXVxeyTQAAgLM27p8+l8/nY9asWfHMM8/EokWLoqGhIR588MHYvHnzGdesX78+enp6hh5HjhwZ720CAACJKuiDFmbOnBklJSXR3d09bLy7uzuqqqpGXDN79uy44IILoqSkZGjsU5/6VHR1dcXAwECUlpaetiaXy0UulytkawAAAKNS0J2i0tLSWLRoUbS3tw+N5fP5aG9vj9ra2hHXXH/99fH2229HPp8fGnvrrbdi9uzZIwYRAADARCr47XONjY2xZcuW+P73vx/79u2Lu+++O/r6+mL16tUREbFy5cpYv3790Py77747fvOb38S9994bb731Vmzfvj02btwYa9asGbtXAQAAMEoFf09RQ0NDHDt2LDZs2BBdXV2xcOHCaGtrG/rwhcOHD0dx8R9aq7q6Ol555ZW477774uqrr465c+fGvffeG/fff//YvQoAAIBRKvh7iiaD7ykCAAAiPgLfUwQAAHC+EUUAAEDSRBEAAJA0UQQAACRNFAEAAEkTRQAAQNJEEQAAkDRRBAAAJE0UAQAASRNFAABA0kQRAACQNFEEAAAkTRQBAABJE0UAAEDSRBEAAJA0UQQAACRNFAEAAEkTRQAAQNJEEQAAkDRRBAAAJE0UAQAASRNFAABA0kQRAACQNFEEAAAkTRQBAABJE0UAAEDSRBEAAJA0UQQAACRNFAEAAEkTRQAAQNJEEQAAkDRRBAAAJE0UAQAASRNFAABA0kQRAACQNFEEAAAkTRQBAABJE0UAAEDSRBEAAJA0UQQAACRNFAEAAEkTRQAAQNJEEQAAkDRRBAAAJE0UAQAASRNFAABA0kQRAACQNFEEAAAkTRQBAABJE0UAAEDSRBEAAJA0UQQAACRNFAEAAEkTRQAAQNJEEQAAkDRRBAAAJE0UAQAASRNFAABA0kQRAACQNFEEAAAkTRQBAABJE0UAAEDSRBEAAJA0UQQAACRNFAEAAEkTRQAAQNJEEQAAkDRRBAAAJE0UAQAASRNFAABA0kQRAACQNFEEAAAkTRQBAABJE0UAAEDSRBEAAJA0UQQAACRNFAEAAEkTRQAAQNJEEQAAkDRRBAAAJE0UAQAASRtVFLW2tsa8efOirKwsampqYteuXWe1buvWrVFUVBTLli0bzWUBAADGXMFRtG3btmhsbIympqbYs2dPLFiwIOrr6+Po0aMfuO7QoUPxta99LW644YZRbxYAAGCsFRxFTzzxRHzlK1+J1atXx6c//enYvHlzTJ8+Pb73ve+dcc3g4GB8+ctfjkceeSQuu+yyc9owAADAWCooigYGBmL37t1RV1f3hycoLo66urro6Og447pvfvObMWvWrLj99tvP6jr9/f3R29s77AEAADAeCoqi48ePx+DgYFRWVg4br6ysjK6urhHX/OxnP4tnn302tmzZctbXaW5ujoqKiqFHdXV1IdsEAAA4a+P66XMnTpyIFStWxJYtW2LmzJlnvW79+vXR09Mz9Dhy5Mg47hIAAEjZtEImz5w5M0pKSqK7u3vYeHd3d1RVVZ02/xe/+EUcOnQoli5dOjSWz+d/f+Fp0+LAgQNx+eWXn7Yul8tFLpcrZGsAAACjUtCdotLS0li0aFG0t7cPjeXz+Whvb4/a2trT5l955ZXxxhtvRGdn59DjS1/6Utx0003R2dnpbXEAAMCkK+hOUUREY2NjrFq1KhYvXhxLliyJlpaW6Ovri9WrV0dExMqVK2Pu3LnR3NwcZWVlMX/+/GHrL7744oiI08YBAAAmQ8FR1NDQEMeOHYsNGzZEV1dXLFy4MNra2oY+fOHw4cNRXDyuv6oEAAAwZoqyLMsmexMfpre3NyoqKqKnpyfKy8snezsAAMAkGY82cEsHAABImigCAACSJooAAICkiSIAACBpoggAAEiaKAIAAJImigAAgKSJIgAAIGmiCAAASJooAgAAkiaKAACApIkiAAAgaaIIAABImigCAACSJooAAICkiSIAACBpoggAAEiaKAIAAJImigAAgKSJIgAAIGmiCAAASJooAgAAkiaKAACApIkiAAAgaaIIAABImigCAACSJooAAICkiSIAACBpoggAAEiaKAIAAJImigAAgKSJIgAAIGmiCAAASJooAgAAkiaKAACApIkiAAAgaaIIAABImigCAACSJooAAICkiSIAACBpoggAAEiaKAIAAJImigAAgKSJIgAAIGmiCAAASJooAgAAkiaKAACApIkiAAAgaaIIAABImigCAACSJooAAICkiSIAACBpoggAAEiaKAIAAJImigAAgKSJIgAAIGmiCAAASJooAgAAkiaKAACApIkiAAAgaaIIAABImigCAACSJooAAICkTZvsDRRiftMrUZybPtnbAAAAJkm+/+SYP6c7RQAAQNJEEQAAkDRRBAAAJE0UAQAASRNFAABA0kQRAACQNFEEAAAkTRQBAABJE0UAAEDSRBEAAJA0UQQAACRNFAEAAEkTRQAAQNJEEQAAkDRRBAAAJE0UAQAASRNFAABA0kQRAACQtFFFUWtra8ybNy/KysqipqYmdu3adca5W7ZsiRtuuCFmzJgRM2bMiLq6ug+cDwAAMJEKjqJt27ZFY2NjNDU1xZ49e2LBggVRX18fR48eHXH+zp07Y/ny5fHaa69FR0dHVFdXx8033xzvvPPOOW8eAADgXBVlWZYVsqCmpiauvfbaePLJJyMiIp/PR3V1ddxzzz2xbt26D10/ODgYM2bMiCeffDJWrlx5Vtfs7e2NioqKqF77QhTnpheyXQAA4DyS7z8ZR1pujZ6enigvLx+T5yzoTtHAwEDs3r076urq/vAExcVRV1cXHR0dZ/UcJ0+ejPfeey8uueSSM87p7++P3t7eYQ8AAIDxUFAUHT9+PAYHB6OysnLYeGVlZXR1dZ3Vc9x///0xZ86cYWH1x5qbm6OiomLoUV1dXcg2AQAAztqEfvrcpk2bYuvWrfHSSy9FWVnZGeetX78+enp6hh5HjhyZwF0CAAApmVbI5JkzZ0ZJSUl0d3cPG+/u7o6qqqoPXPvYY4/Fpk2b4ic/+UlcffXVHzg3l8tFLpcrZGsAAACjUtCdotLS0li0aFG0t7cPjeXz+Whvb4/a2tozrvvOd74Tjz76aLS1tcXixYtHv1sAAIAxVtCdooiIxsbGWLVqVSxevDiWLFkSLS0t0dfXF6tXr46IiJUrV8bcuXOjubk5IiL+8R//MTZs2BDPP/98zJs3b+h3jz72sY/Fxz72sTF8KQAAAIUrOIoaGhri2LFjsWHDhujq6oqFCxdGW1vb0IcvHD58OIqL/3AD6umnn46BgYH467/+62HP09TUFN/4xjfObfcAAADnqODvKZoMvqcIAACI+Ah8TxEAAMD5RhQBAABJE0UAAEDSRBEAAJA0UQQAACRNFAEAAEkTRQAAQNJEEQAAkDRRBAAAJE0UAQAASRNFAABA0kQRAACQNFEEAAAkTRQBAABJE0UAAEDSRBEAAJA0UQQAACRNFAEAAEkTRQAAQNJEEQAAkDRRBAAAJE0UAQAASRNFAABA0kQRAACQNFEEAAAkTRQBAABJE0UAAEDSRBEAAJA0UQQAACRNFAEAAEkTRQAAQNJEEQAAkDRRBAAAJE0UAQAASRNFAABA0kQRAACQNFEEAAAkTRQBAABJE0UAAEDSRBEAAJA0UQQAACRNFAEAAEkTRQAAQNJEEQAAkDRRBAAAJE0UAQAASRNFAABA0kQRAACQNFEEAAAkTRQBAABJE0UAAEDSRBEAAJA0UQQAACRNFAEAAEkTRQAAQNJEEQAAkDRRBAAAJE0UAQAASRNFAABA0kQRAACQNFEEAAAkTRQBAABJE0UAAEDSRBEAAJA0UQQAACRNFAEAAEkTRQAAQNJEEQAAkDRRBAAAJE0UAQAASRNFAABA0kQRAACQNFEEAAAkTRQBAABJE0UAAEDSRBEAAJA0UQQAACRNFAEAAEkTRQAAQNJEEQAAkDRRBAAAJG1UUdTa2hrz5s2LsrKyqKmpiV27dn3g/B/84Adx5ZVXRllZWVx11VWxY8eOUW0WAABgrBUcRdu2bYvGxsZoamqKPXv2xIIFC6K+vj6OHj064vzXX389li9fHrfffnvs3bs3li1bFsuWLYs333zznDcPAABwroqyLMsKWVBTUxPXXnttPPnkkxERkc/no7q6Ou65555Yt27dafMbGhqir68vfvzjHw+N/eVf/mUsXLgwNm/efFbX7O3tjYqKiqhe+0IU56YXsl0AAOA8ku8/GUdabo2enp4oLy8fk+ecVsjkgYGB2L17d6xfv35orLi4OOrq6qKjo2PENR0dHdHY2DhsrL6+Pl5++eUzXqe/vz/6+/uHfu7p6YmI3/8NAAAA0vV+ExR4b+cDFRRFx48fj8HBwaisrBw2XllZGfv37x9xTVdX14jzu7q6znid5ubmeOSRR04bf+fpvy1kuwAAwHnqv//7v6OiomJMnqugKJoo69evH3Z36d13342Pf/zjcfjw4TF74TCS3t7eqK6ujiNHjozZ7VgYibPGRHHWmCjOGhOlp6cnLr300rjkkkvG7DkLiqKZM2dGSUlJdHd3Dxvv7u6OqqqqEddUVVUVND8iIpfLRS6XO228oqLCP2RMiPLycmeNCeGsMVGcNSaKs8ZEKS4eu28XKuiZSktLY9GiRdHe3j40ls/no729PWpra0dcU1tbO2x+RMSrr756xvkAAAATqeC3zzU2NsaqVati8eLFsWTJkmhpaYm+vr5YvXp1RESsXLky5s6dG83NzRERce+998aNN94Yjz/+eNxyyy2xdevW+PnPfx7PPPPM2L4SAACAUSg4ihoaGuLYsWOxYcOG6OrqioULF0ZbW9vQhykcPnx42K2s6667Lp5//vl46KGH4oEHHoi/+Iu/iJdffjnmz59/1tfM5XLR1NQ04lvqYCw5a0wUZ42J4qwxUZw1Jsp4nLWCv6cIAADgfDJ2v50EAAAwBYkiAAAgaaIIAABImigCAACS9pGJotbW1pg3b16UlZVFTU1N7Nq16wPn/+AHP4grr7wyysrK4qqrroodO3ZM0E6Z6go5a1u2bIkbbrghZsyYETNmzIi6uroPPZvwvkL/XHvf1q1bo6ioKJYtWza+G+S8UehZe/fdd2PNmjUxe/bsyOVyccUVV/j3KGel0LPW0tISn/zkJ+PCCy+M6urquO++++J3v/vdBO2WqeinP/1pLF26NObMmRNFRUXx8ssvf+ianTt3xmc/+9nI5XLxiU98Ip577rmCr/uRiKJt27ZFY2NjNDU1xZ49e2LBggVRX18fR48eHXH+66+/HsuXL4/bb7899u7dG8uWLYtly5bFm2++OcE7Z6op9Kzt3Lkzli9fHq+99lp0dHREdXV13HzzzfHOO+9M8M6Zago9a+87dOhQfO1rX4sbbrhhgnbKVFfoWRsYGIgvfOELcejQoXjxxRfjwIEDsWXLlpg7d+4E75ypptCz9vzzz8e6deuiqakp9u3bF88++2xs27YtHnjggQneOVNJX19fLFiwIFpbW89q/i9/+cu45ZZb4qabborOzs5Yu3Zt3HHHHfHKK68UduHsI2DJkiXZmjVrhn4eHBzM5syZkzU3N484/9Zbb81uueWWYWM1NTXZ3/3d343rPpn6Cj1rf+zUqVPZRRddlH3/+98fry1ynhjNWTt16lR23XXXZd/97nezVatWZX/1V381ATtlqiv0rD399NPZZZddlg0MDEzUFjlPFHrW1qxZk33+858fNtbY2Jhdf/3147pPzh8Rkb300ksfOOfrX/969pnPfGbYWENDQ1ZfX1/QtSb9TtHAwEDs3r076urqhsaKi4ujrq4uOjo6RlzT0dExbH5ERH19/RnnQ8ToztofO3nyZLz33ntxySWXjNc2OQ+M9qx985vfjFmzZsXtt98+EdvkPDCas/ajH/0oamtrY82aNVFZWRnz58+PjRs3xuDg4ERtmyloNGftuuuui927dw+9xe7gwYOxY8eO+OIXvzgheyYNY9UF08ZyU6Nx/PjxGBwcjMrKymHjlZWVsX///hHXdHV1jTi/q6tr3PbJ1Deas/bH7r///pgzZ85p//DB/zeas/azn/0snn322ejs7JyAHXK+GM1ZO3jwYPz7v/97fPnLX44dO3bE22+/HV/96lfjvffei6amponYNlPQaM7abbfdFsePH4/Pfe5zkWVZnDp1Ku666y5vn2NMnakLent747e//W1ceOGFZ/U8k36nCKaKTZs2xdatW+Oll16KsrKyyd4O55ETJ07EihUrYsuWLTFz5szJ3g7nuXw+H7NmzYpnnnkmFi1aFA0NDfHggw/G5s2bJ3trnGd27twZGzdujKeeeir27NkTP/zhD2P79u3x6KOPTvbW4DSTfqdo5syZUVJSEt3d3cPGu7u7o6qqasQ1VVVVBc2HiNGdtfc99thjsWnTpvjJT34SV1999Xhuk/NAoWftF7/4RRw6dCiWLl06NJbP5yMiYtq0aXHgwIG4/PLLx3fTTEmj+XNt9uzZccEFF0RJScnQ2Kc+9ano6uqKgYGBKC0tHdc9MzWN5qw9/PDDsWLFirjjjjsiIuKqq66Kvr6+uPPOO+PBBx+M4mL/b55zd6YuKC8vP+u7RBEfgTtFpaWlsWjRomhvbx8ay+fz0d7eHrW1tSOuqa2tHTY/IuLVV18943yIGN1Zi4j4zne+E48++mi0tbXF4sWLJ2KrTHGFnrUrr7wy3njjjejs7Bx6fOlLXxr6JJ3q6uqJ3D5TyGj+XLv++uvj7bffHgrviIi33norZs+eLYg4o9GctZMnT54WPu/H+O9/hx7O3Zh1QWGfATE+tm7dmuVyuey5557L/uu//iu78847s4svvjjr6urKsizLVqxYka1bt25o/n/8x39k06ZNyx577LFs3759WVNTU3bBBRdkb7zxxmS9BKaIQs/apk2bstLS0uzFF1/Mfv3rXw89Tpw4MVkvgSmi0LP2x3z6HGer0LN2+PDh7KKLLsr+/u//Pjtw4ED24x//OJs1a1b2rW99a7JeAlNEoWetqakpu+iii7J//dd/zQ4ePJj927/9W3b55Zdnt95662S9BKaAEydOZHv37s327t2bRUT2xBNPZHv37s1+9atfZVmWZevWrctWrFgxNP/gwYPZ9OnTs3/4h3/I9u3bl7W2tmYlJSVZW1tbQdf9SERRlmXZP//zP2eXXnppVlpami1ZsiT7z//8z6G/duONN2arVq0aNv+FF17Irrjiiqy0tDT7zGc+k23fvn2Cd8xUVchZ+/jHP55FxGmPpqamid84U06hf679f6KIQhR61l5//fWspqYmy+Vy2WWXXZZ9+9vfzk6dOjXBu2YqKuSsvffee9k3vvGN7PLLL8/Kysqy6urq7Ktf/Wr2P//zPxO/caaM1157bcT/9nr/bK1atSq78cYbT1uzcOHCrLS0NLvsssuyf/mXfyn4ukVZ5v4lAACQrkn/nSIAAIDJJIoAAICkiSIAACBpoggAAEiaKAIAAJImigAAgKSJIgAAIGmiCAAASJooAgAAkiaKAACApIkiAAAgaaIIAABI2v8BXJgIWVswS60AAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df.plot(kind='barh', figsize=(10,6))\n",
    "plt.xlabel('Document Frequency')\n",
    "plt.ylabel('Token ID')\n",
    "plt.title('Top 20 Tokens by Document Frequency')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (env)",
   "language": "python",
   "name": "env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
