{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "751e8501",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af2cd081",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "from transformers import AutoTokenizer\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5daf5a96",
   "metadata": {},
   "source": [
    "## General Stats "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f3781de9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 100%|██████████| 25000/25000 [00:02<00:00, 12065.85 examples/s]\n",
      "Generating test split: 100%|██████████| 25000/25000 [00:00<00:00, 35535.41 examples/s]\n",
      "Generating unsupervised split: 100%|██████████| 50000/50000 [00:01<00:00, 35279.38 examples/s]\n"
     ]
    }
   ],
   "source": [
    "# SST-2 (GLUE)\n",
    "sst2 = load_dataset(\"glue\", \"sst2\")\n",
    "\n",
    "# IMDb\n",
    "imdb = load_dataset(\"imdb\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "51f2a502",
   "metadata": {},
   "outputs": [],
   "source": [
    "sst2_train_size = len(sst2[\"train\"])\n",
    "sst2_val_size   = len(sst2[\"validation\"])\n",
    "sst2_test_size  = len(sst2[\"test\"])\n",
    "\n",
    "imdb_train_size = len(imdb[\"train\"])\n",
    "imdb_test_size  = len(imdb[\"test\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d40c2e7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0248d922",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 67349/67349 [00:15<00:00, 4260.54 examples/s]\n",
      "Map: 100%|██████████| 872/872 [00:00<00:00, 3178.30 examples/s]\n",
      "Map: 100%|██████████| 1821/1821 [00:00<00:00, 3497.87 examples/s]\n"
     ]
    }
   ],
   "source": [
    "def add_len_sst2(example):\n",
    "    tokens = tokenizer(\n",
    "        example[\"sentence\"],\n",
    "        truncation=False,\n",
    "        add_special_tokens=True\n",
    "    )\n",
    "    example[\"seq_len\"] = len(tokens[\"input_ids\"])\n",
    "    return example\n",
    "\n",
    "sst2_with_len = sst2.map(add_len_sst2, batched=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "486f2c94",
   "metadata": {},
   "outputs": [],
   "source": [
    "def length_stats(dataset, split):\n",
    "    lengths = np.array(dataset[split][\"seq_len\"])\n",
    "    return {\n",
    "        \"median\": int(np.median(lengths)),\n",
    "        \"mean\": float(np.mean(lengths)),\n",
    "        \"min\": int(np.min(lengths)),\n",
    "        \"max\": int(np.max(lengths)),\n",
    "    }\n",
    "\n",
    "sst2_train_stats = length_stats(sst2_with_len, \"train\")\n",
    "sst2_val_stats   = length_stats(sst2_with_len, \"validation\")\n",
    "sst2_test_stats  = length_stats(sst2_with_len, \"test\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "24e84718",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'median': 10, 'mean': 13.319262349849293, 'min': 3, 'max': 66}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sst2_train_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5408b718",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'median': 24, 'mean': 25.163990825688074, 'min': 4, 'max': 55}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sst2_val_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b593296d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 25000/25000 [00:28<00:00, 870.15 examples/s]\n",
      "Map: 100%|██████████| 12500/12500 [00:14<00:00, 848.97 examples/s]\n",
      "Map: 100%|██████████| 12500/12500 [00:14<00:00, 841.08 examples/s]\n"
     ]
    }
   ],
   "source": [
    "def add_len_imdb(example):\n",
    "    tokens = tokenizer(\n",
    "        example[\"text\"],\n",
    "        truncation=False,\n",
    "        add_special_tokens=True\n",
    "    )\n",
    "    example[\"seq_len\"] = len(tokens[\"input_ids\"])\n",
    "    return example\n",
    "\n",
    "split = imdb[\"test\"].train_test_split(test_size=0.5, seed=42, stratify_by_column=\"label\")\n",
    "\n",
    "imdb[\"validation\"] = split[\"train\"]   # becomes validation set\n",
    "imdb[\"test\"] = split[\"test\"]          \n",
    "imdb_with_len = imdb.map(add_len_imdb, batched=False)\n",
    "\n",
    "imdb_train_stats = length_stats(imdb_with_len, \"train\")\n",
    "imdb_test_stats  = length_stats(imdb_with_len, \"validation\")  # renamed to validation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "76fefb80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'median': 233, 'mean': 313.87132, 'min': 13, 'max': 3127}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imdb_train_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c500db35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'median': 232, 'mean': 309.53296, 'min': 10, 'max': 3157}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imdb_test_stats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa50d1ed",
   "metadata": {},
   "source": [
    "# Top Tokens "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f3696e85",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bfb548a",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('/home/anonuser/thesis')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "76795dfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "token_stats_file = 'results/sst2_bert_token_counts.json'\n",
    "with open(token_stats_file, 'r') as f:\n",
    "    token_stats = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4f01c163",
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_stats = token_stats['1']\n",
    "neg_stats = token_stats['0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70b72884",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def extract_counts(nested_stats):\n",
    "    # sum inner dict counts to be robust (handles multiple tokens per id)\n",
    "    return np.array([sum(inner.values()) for inner in nested_stats.values()], dtype=int)\n",
    "\n",
    "pos_counts = extract_counts(pos_stats)\n",
    "neg_counts = extract_counts(neg_stats)\n",
    "\n",
    "# Print basic summary\n",
    "print(\"POS counts: n={}, mean={:.2f}, median={}, min={}, max={}\".format(\n",
    "    len(pos_counts), pos_counts.mean(), int(np.median(pos_counts)), pos_counts.min(), pos_counts.max()))\n",
    "print(\"NEG counts: n={}, mean={:.2f}, median={}, min={}, max={}\".format(\n",
    "    len(neg_counts), neg_counts.mean(), int(np.median(neg_counts)), neg_counts.min(), neg_counts.max()))\n",
    "\n",
    "# Setup figure\n",
    "fig, axes = plt.subplots(2, , figsize=(12, 8)) # anon bug? \n",
    "ax_hist_pos, ax_hist_neg, ax_box, ax_ecdf = axes.flatten()\n",
    "\n",
    "# Log-spaced bins for heavy-tailed counts\n",
    "max_count = max(pos_counts.max(), neg_counts.max())\n",
    "bins = np.logspace(0, np.log10(max_count + 1), 40)\n",
    "\n",
    "ax_hist_pos.hist(pos_counts, bins=bins, color='C0', alpha=0.7)\n",
    "ax_hist_pos.set_xscale('log')\n",
    "ax_hist_pos.set_title('Positive tokens: histogram (log x)')\n",
    "ax_hist_pos.set_xlabel('count')\n",
    "ax_hist_pos.set_ylabel('frequency')\n",
    "\n",
    "ax_hist_neg.hist(neg_counts, bins=bins, color='C1', alpha=0.7)\n",
    "ax_hist_neg.set_xscale('log')\n",
    "ax_hist_neg.set_title('Negative tokens: histogram (log x)')\n",
    "ax_hist_neg.set_xlabel('count')\n",
    "ax_hist_neg.set_ylabel('frequency')\n",
    "\n",
    "# Boxplot on log1p(count) to visualize center/spread\n",
    "sns.boxplot(data=[np.log1p(pos_counts), np.log1p(neg_counts)], ax=ax_box)\n",
    "ax_box.set_xticklabels(['pos', 'neg'])\n",
    "ax_box.set_ylabel('log1p(count)')\n",
    "ax_box.set_title('Boxplot of log1p(count)')\n",
    "\n",
    "# ECDFs for full-distribution comparison (log x axis)\n",
    "sns.ecdfplot(pos_counts, ax=ax_ecdf, label='pos', stat='proportion')\n",
    "sns.ecdfplot(neg_counts, ax=ax_ecdf, label='neg', stat='proportion')\n",
    "ax_ecdf.set_xscale('log')\n",
    "ax_ecdf.set_xlabel('count')\n",
    "ax_ecdf.set_title('ECDF (log x)')\n",
    "ax_ecdf.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "17adee3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[np.int64(5892),\n",
       " np.int64(5306),\n",
       " np.int64(644),\n",
       " np.int64(466),\n",
       " np.int64(396),\n",
       " np.int64(311),\n",
       " np.int64(235),\n",
       " np.int64(214),\n",
       " np.int64(212),\n",
       " np.int64(182),\n",
       " np.int64(171),\n",
       " np.int64(164),\n",
       " np.int64(160),\n",
       " np.int64(152),\n",
       " np.int64(137),\n",
       " np.int64(133),\n",
       " np.int64(131),\n",
       " np.int64(129),\n",
       " np.int64(128),\n",
       " np.int64(121)]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(neg_counts, reverse=True)[:20]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "code-search",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
